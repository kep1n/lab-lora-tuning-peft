{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kep1n/lab-lora-tuning-peft/blob/main/lab-lora-tuning-peft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlflow"
      ],
      "metadata": {
        "collapsed": true,
        "id": "SFnVC1jrceMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "from google.colab import userdata\n",
        "uri = userdata.get('MLFLOW_TRACKING_URI')\n",
        "username = userdata.get('username')\n",
        "password = userdata.get('password')"
      ],
      "metadata": {
        "id": "LLEzfucWcp-z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Specify the tracking server URI, e.g. http://localhost:5000\n",
        "mlflow.set_tracking_uri(uri)\n",
        "# If the experiment with the name \"traces-quickstart\" doesn't exist, MLflow will create it\n",
        "mlflow.set_experiment(\"lab-lora-tuning-peft\")\n",
        "mlflow.autolog()"
      ],
      "metadata": {
        "id": "UK-sNWKAcMCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9Y40X0WCY_H"
      },
      "source": [
        "# Lab | Introduction to LoRA Tuning using PEFT from Hugging Face\n",
        "<!-- ### Fine-tune a Foundational Model effortlessly -->\n",
        "\n",
        "**Note:** This is more or less the same notebook you saw in the previous lesson, but that is ok. This is an LLM fine-tuning lab. In class we used a set of datasets and models, and in the labs you are required to change the LLMs models and the datasets including the pre-processing pipelines.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCinY2l-upqy"
      },
      "source": [
        "# LoRA Tuning\n",
        "\n",
        "In this notebook you are being introduced to how to apply LoRA Tuning with the PEFT library to a pre-trained model.\n",
        "\n",
        "For a complete list of Models compatible with PEFT refer to their [documentation](https://huggingface.co/docs/peft/main/en/index#supported-methods).\n",
        "\n",
        "A short sample of models families available to be trained with PEFT are: Bloom, Llama, GPT-J, GPT-2, BERT... and more. Hugging Face is working hard to bring more Models to the Library.\n",
        "\n",
        "## Brief introduction to LoRA Tuning.\n",
        "LoRA is a re-parameterization technique. Its operation is simple, complex, and brilliant at the same time. It involves reducing the size of the matrices to be trained by dividing them in such a way that when multiplied, they yield the original matrix.\n",
        "\n",
        "The weights that are modified are those of the reduced matrices, not the original matrix. It's better visualized in an image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cp_7rR4Nx7My"
      },
      "source": [
        "![Matrices_LoRA.webp](data:image/webp;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oSLJkXty-t_"
      },
      "source": [
        "We have an original matrix of 50x50, which means we would have to modify about 2500 parameters. However, as we know, if we multiply two matrices of (2x50) and (50x2), we obtain a 50x50 matrix. Yet, these two matrices are formed by only 100 parameters each. In other words, for the reduced matrices, we need to modify a total of 200 parameters compared to the 2500 of the original matrix. This represents a 92% reduction, and the larger the original matrix, the greater the percentage of savings.\n",
        "\n",
        "In Language Models like GPT-3 or any of the current ones with LoRA, it's possible that we only need to train about 0.02% of the original parameters. This varies for each model. The best part is that the obtained result is very similar to that of full fine-tuning, in some cases, it can even be better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "620MdVMk7iUS"
      },
      "source": [
        "# Load the PEFT and Datasets Libraries.\n",
        "\n",
        "The PEFT library contains the Hugging Face implementation of differente fine-tuning techniques, like LoRA Tuning.\n",
        "\n",
        "Using the Datasets library we have acces to a huge amount of Datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UyyuMGnCPjA",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# !pip install -q peft==0.8.2\n",
        "# !pip install -q datasets==2.16.1\n",
        "#!pip install ipywidgets==7.7.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOnJlBY-81Wl"
      },
      "source": [
        "From the transformers library we import the necesary classes to import the model and the tokenizer.\n",
        "\n",
        "Then we can load the Tokenizer and the model.\n",
        "\n",
        "Bloom is one of the smallest and smarter model available to be trained with PEFT Library using Prompt Tuning. You can use either of the models in the Bloom Family, I encorage you to use at least two of them and see the differences.\n",
        "\n",
        "I'm using the smallest one just to spend less time trainig, and avoid memory problems in Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "vziwd2UuCYGl",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model_name = \"bigscience/bloom-560m\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "foundation_model = AutoModelForCausalLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qtc1gbK39Hp7"
      },
      "source": [
        "## Inference with the pre-trained model.\n",
        "I'm going to do a test with the pre-trained model without fine-tuning, to see if something changes after the fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jak6FzpvFTHk",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#this function returns the outputs from the model received, and inputs.\n",
        "def get_outputs(model, inputs, max_new_tokens=100): #play with this function inputs and see if you get something interesting\n",
        "    outputs = model.generate(\n",
        "        input_ids=inputs[\"input_ids\"],\n",
        "        attention_mask=inputs[\"attention_mask\"],\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        repetition_penalty=1.5, #Avoid repetition.\n",
        "        early_stopping=True, #The model can stop before reach the max_length\n",
        "        eos_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkFqjS459jAa"
      },
      "source": [
        "The dataset used for the fine-tuning contains prompts to be used with Large Language Models.\n",
        "\n",
        "I'm going to request the pre-trained model that acts like a motivational coach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BAYg7czFYeK",
        "outputId": "118b5dd2-ee71-4622-f4e1-4dd35cf0f2d7",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I want you to act as a professional motivational coach the/api//api other others = whom I  like mind another who diagnos diagnosis diagnostic diagnisp speech acts providing them persons provide meability probinging/ reply method it self detects recognition ability abilities humans we but also everyone else { they i myself only one respond']\n"
          ]
        }
      ],
      "source": [
        "#Inference original model\n",
        "input_sentences = tokenizer(\"I want you to act as a professional motivational coach\", return_tensors=\"pt\").to('cuda')\n",
        "foundational_outputs_sentence = get_outputs(foundation_model, input_sentences, max_new_tokens=50)\n",
        "\n",
        "print(tokenizer.batch_decode(foundational_outputs_sentence, skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQUGY47p9ysI"
      },
      "source": [
        "Not sure if the answer is correct or not, but for sure is not a prompt. We need to train our model if we want that acts like a prompt engineer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL5L_DcR9ggA"
      },
      "source": [
        "# Preparing the Dataset.\n",
        "The Dataset used is:\n",
        "\n",
        "https://huggingface.co/datasets/fka/awesome-chatgpt-prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "80674eb6afe14df9869318218b6b4933",
            "8a940bda862c4ea082914122d2c4ba45",
            "bd5558eba6984e43afc4506119d15f11",
            "d00c11fc4dee4c6987988f1dd516ce3c",
            "0ac6cc32fb6e4940a90165248e3e403b",
            "5fc6bacae7684b12b78c427dbc35d875",
            "3c27ba426033499baa794beb8aa7761a",
            "44e11f3d154a4f51a605c9bee400f542",
            "28b4a2ee7e6d4a8287b32c7379936ac9",
            "cc63874f46464af0b6b3fff28a71c45e",
            "8f0fbd8d9af34f41b2f97512eced21df"
          ]
        },
        "id": "DyIMQ7IHFbIx",
        "outputId": "0be21b32-3a47-4753-d593-ba105516fc3f",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/513 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80674eb6afe14df9869318218b6b4933"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['prompt', 'for_devs', 'type', 'contributor', 'input_ids', 'attention_mask'],\n",
              "    num_rows: 50\n",
              "})"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "dataset = \"fka/awesome-chatgpt-prompts\"\n",
        "\n",
        "#Create the Dataset to create prompts.\n",
        "data = load_dataset(dataset)\n",
        "data = data.map(lambda samples: tokenizer(samples[\"prompt\"]), batched=True)\n",
        "train_sample = data[\"train\"].select(range(50))\n",
        "\n",
        "train_sample = train_sample.remove_columns('act')\n",
        "\n",
        "display(train_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmlZY3fk_9fm",
        "outputId": "8e39390f-ed78-40a9-c399-e51c3780a121",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'prompt': ['Imagine you are an experienced Ethereum developer tasked with creating a smart contract for a blockchain messenger. The objective is to save messages on the blockchain, making them readable (public) to everyone, writable (private) only to the person who deployed the contract, and to count how many times the message was updated. Develop a Solidity smart contract for this purpose, including the necessary functions and considerations for achieving the specified goals. Please provide the code and any relevant explanations to ensure a clear understanding of the implementation.'], 'for_devs': [True], 'type': ['TEXT'], 'contributor': ['ameya-2003'], 'input_ids': [[186402, 1152, 1306, 660, 72560, 28857, 167625, 84544, 20165, 376, 1002, 26168, 267, 30479, 17477, 613, 267, 120755, 238776, 17, 1387, 47881, 632, 427, 14565, 29866, 664, 368, 120755, 15, 16997, 4054, 136044, 375, 4859, 12, 427, 39839, 15, 9697, 1242, 375, 13614, 12, 3804, 427, 368, 2298, 5268, 109891, 368, 17477, 15, 530, 427, 11210, 4143, 7112, 11866, 368, 11011, 1620, 36320, 17, 21265, 267, 11550, 90533, 30479, 17477, 613, 1119, 27343, 15, 11762, 368, 18348, 16231, 530, 127246, 613, 94510, 368, 25605, 55790, 17, 29901, 13842, 368, 4400, 530, 2914, 24466, 184637, 427, 22646, 267, 11285, 32391, 461, 368, 17786, 17]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
          ]
        }
      ],
      "source": [
        "print(train_sample[:1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVPAJsrUAHiJ"
      },
      "source": [
        "# Fine-Tuning.\n",
        "First is necesary create a LoRA config.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwAK6kxCDCfM"
      },
      "source": [
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uCalslQFGL7K"
      },
      "outputs": [],
      "source": [
        "# TARGET_MODULES\n",
        "# https://github.com/huggingface/peft/blob/39ef2546d5d9b8f5f8a7016ec10657887a867041/src/peft/utils/other.py#L220\n",
        "\n",
        "import peft\n",
        "from peft import LoraConfig, get_peft_model, PeftModel\n",
        "\n",
        "lora_config = LoraConfig(#play with these config inputs\n",
        "    r=4, #As bigger the R bigger the parameters to train.\n",
        "    lora_alpha=1, # a scaling factor that adjusts the magnitude of the weight matrix. Usually set to 1\n",
        "    target_modules=[\"query_key_value\"], #You can obtain a list of target modules in the URL above.\n",
        "    lora_dropout=0.05, #Helps to avoid Overfitting.\n",
        "    bias=\"lora_only\", # this specifies if the bias parameter should be trained.\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUddynl0B1Ck"
      },
      "source": [
        "The most important parameter is **r**, it defines how many parameters will be trained. As bigger the valuer more parameters are trained, but it means that the model will be able to learn more complicated relations between input and output.\n",
        "\n",
        "Yo can find a list of the **target_modules** available on the [Hugging Face Documentation]( https://github.com/huggingface/peft/blob/39ef2546d5d9b8f5f8a7016ec10657887a867041/src/peft/utils/other.py#L220)\n",
        "\n",
        "**lora_dropout** is like the commom dropout is used to avoid overfitting.\n",
        "\n",
        "**bias** I was hesitating if use *none* or *lora_only*. For text classification the most common value is none, and for chat or question answering, *all* or *lora_only*.\n",
        "\n",
        "**task_type**. Indicates the task the model is beign trained for. In this case, text generation.\n",
        "\n",
        "### Create the PEFT model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BG1zBmhsGQ-h",
        "outputId": "63858d23-77df-4ed3-bd36-32c91aa28f89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 860,160 || all params: 560,001,024 || trainable%: 0.1536\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/peft/mapping_func.py:72: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "peft_model = get_peft_model(foundation_model, lora_config)\n",
        "print(peft_model.print_trainable_parameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2onXUsaw-Ga0"
      },
      "source": [
        "The number of trainable parameters is really small compared with the total number of parameters in the pre-trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "HArPQ_lvGUkY"
      },
      "outputs": [],
      "source": [
        "#Create a directory to contain the Model\n",
        "import os\n",
        "working_dir = './'\n",
        "\n",
        "output_directory = os.path.join(working_dir, \"peft_lab_outputs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWalmqWm4STo"
      },
      "source": [
        "In the TrainingArgs we inform the number of epochs we want to train, the output directory and the learning_rate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ND0aJ-t6ARqD"
      },
      "outputs": [],
      "source": [
        "#Creating the TrainingArgs\n",
        "import transformers\n",
        "from transformers import TrainingArguments, Trainer\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_directory,\n",
        "    auto_find_batch_size=True, # Find a correct batch size that fits the size of Data.\n",
        "    learning_rate= 3e-2, # Higher learning rate than full fine-tuning.\n",
        "    num_train_epochs=2,\n",
        "    use_cpu=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgxsV-iy_J_o"
      },
      "source": [
        "Now we can train the model.\n",
        "To train the model we need:\n",
        "\n",
        "\n",
        "*   The PEFT Model.\n",
        "*   The training_args\n",
        "* The Dataset\n",
        "* The result of DataCollator, the Dataset ready to be procesed in blocks.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.init(mode='disabled')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "EHJdUPppgdQG",
        "outputId": "dc1878ec-1bb5-433a-a405-89f6bce49f49"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dummy/dummy/runs/50jjleiq?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x79a190997c80>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "z5NYHqBnGZyF",
        "outputId": "dca169bb-6021-40da-cdda-6eca656f185d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [14/14 10:20, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèÉ View run illustrious-toad-858 at: https://mlflow.worldwidecheps.synology.me/#/experiments/1/runs/c3e8ee508ed04f7bb48e8dfbedd8f581\n",
            "üß™ View experiment at: https://mlflow.worldwidecheps.synology.me/#/experiments/1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=14, training_loss=6.682071140834263, metrics={'train_runtime': 665.2716, 'train_samples_per_second': 0.15, 'train_steps_per_second': 0.021, 'total_flos': 20483556163584.0, 'train_loss': 6.682071140834263, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "#This cell may take up to 15 minutes to execute.\n",
        "trainer = Trainer(\n",
        "    model=peft_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_sample,\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "kEKiFdpDGgOx"
      },
      "outputs": [],
      "source": [
        "#Save the model.\n",
        "peft_model_path = os.path.join(output_directory, f\"lora_model\")\n",
        "\n",
        "trainer.model.save_pretrained(peft_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_TAjrSWSe14q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cc34a75-c2b4-4966-9b0f-769c76ff478c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#Load the Model.\n",
        "loaded_model = PeftModel.from_pretrained(foundation_model,\n",
        "                                        peft_model_path,\n",
        "                                        is_trainable=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dK--YFPR6OxH"
      },
      "source": [
        "## Inference the fine-tuned model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_27uvJudf03",
        "outputId": "fcf60293-e202-4cd0-dc35-9ae94e78382d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I want you to act as a professional motivational coach. I will be the first person in my life, and that is why it should not have any personality or lifestyle style of your own personalities for me personally speaking about myself with an \"I\" theme! My Life Style: The best way out there']\n"
          ]
        }
      ],
      "source": [
        "input_sentences = tokenizer(\"I want you to act as a professional motivational coach\", return_tensors=\"pt\")\n",
        "foundational_outputs_sentence = get_outputs(loaded_model, input_sentences, max_new_tokens=50)\n",
        "\n",
        "print(tokenizer.batch_decode(foundational_outputs_sentence, skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCV9JOBG6Ug8"
      },
      "source": [
        "The result is amazing. Let's compare the answer of the pre-trained Model withe the one fine-tuned by us using LoRA:\n",
        "* **Pretrained Model:** *I want you to act as a motivational coach.*  Don't be afraid of being challenged.\n",
        "* **Fine-Tuned Model:** I want you to act as a motivational coach.  I will provide some information about someone\\'s motivation and goals, but it should be your job  in order my first request ‚Äì \"I need someone who can help me find the best way for myself stay motivated when competing against others.\" My suggestion is ‚ÄúI have\n",
        "\n",
        "As you can see the result is really similar to the samples containmed in the Datased used to fine-tune the Model. And we only trained the Model for 10 epochs and with a really small number of rows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tr4Sm32y89Ji"
      },
      "source": [
        "# Exercise\n",
        "\n",
        "- Drive your own experiments with all the variables and different model types.\n",
        "    - Please with the **lora_config** values, maybe you can achieve a better result in less epochs, saving time and money for your company. :-)\n",
        "- Write a one page report\n",
        "    - What did you learn?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lora_config = LoraConfig(#play with these config inputs\n",
        "    r=4, #As bigger the R bigger the parameters to train.\n",
        "    lora_alpha=1, # a scaling factor that adjusts the magnitude of the weight matrix. Usually set to 1\n",
        "    target_modules=[\"query_key_value\"], #You can obtain a list of target modules in the URL above.\n",
        "    lora_dropout=0.1, #Helps to avoid Overfitting.\n",
        "    bias=\"lora_only\", # this specifies if the bias parameter should be trained.\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "peft_model = get_peft_model(foundation_model, lora_config)\n",
        "print(peft_model.print_trainable_parameters())\n"
      ],
      "metadata": {
        "id": "bHbb2k3Us8m6",
        "outputId": "19834cca-e345-4615-fac7-24cfa6356d02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 466,944 || all params: 559,607,808 || trainable%: 0.0834\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "IlXxTJO_b9zR",
        "outputId": "3258d38b-e64b-488e-a9e5-a140a165526d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [35/35 00:22, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/12/23 10:26:09 ERROR mlflow.utils.async_logging.async_logging_queue: Run Id fc04433a7f6f407fb664c264002ba8e7: Failed to log run data: Exception: INVALID_PARAMETER_VALUE: The run fc04433a7f6f407fb664c264002ba8e7 must be in the 'active' state. Current state is deleted.\n",
            "2025/12/23 10:26:09 ERROR mlflow.utils.async_logging.async_logging_queue: Run Id fc04433a7f6f407fb664c264002ba8e7: Failed to log run data: Exception: INVALID_PARAMETER_VALUE: The run fc04433a7f6f407fb664c264002ba8e7 must be in the 'active' state. Current state is deleted.\n",
            "2025/12/23 10:26:10 ERROR mlflow.utils.async_logging.async_logging_queue: Run Id fc04433a7f6f407fb664c264002ba8e7: Failed to log run data: Exception: INVALID_PARAMETER_VALUE: The run fc04433a7f6f407fb664c264002ba8e7 must be in the 'active' state. Current state is deleted.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=35, training_loss=2.493794250488281, metrics={'train_runtime': 23.3561, 'train_samples_per_second': 10.704, 'train_steps_per_second': 1.499, 'total_flos': 50803868860416.0, 'train_loss': 2.493794250488281, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "#Creating the TrainingArgs\n",
        "import transformers\n",
        "from transformers import TrainingArguments, Trainer\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_directory,\n",
        "    auto_find_batch_size=True, # Find a correct batch size that fits the size of Data.\n",
        "    learning_rate= 3e-3, # Higher learning rate than full fine-tuning.\n",
        "    num_train_epochs=5,\n",
        "    use_cpu=False\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=peft_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_sample,\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the Model.\n",
        "loaded_model = PeftModel.from_pretrained(foundation_model,\n",
        "                                        peft_model_path,\n",
        "                                        is_trainable=False)\n",
        "input_sentences = tokenizer(\"I want you to act as a professional motivational coach\", return_tensors=\"pt\").to('cuda')\n",
        "foundational_outputs_sentence = get_outputs(loaded_model, input_sentences, max_new_tokens=50)\n",
        "\n",
        "print(tokenizer.batch_decode(foundational_outputs_sentence, skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "QOzw4ZHor2rW",
        "outputId": "644ac3bd-96c9-4efd-c277-3e88920882a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I want you to act as a professional motivational coach. ‡≤ó- Nugroho Nugroho NugrohoTetPekeraldoeraldoeraldoDesaKwaIstrKut\"DiaËµÑÊñôkateNTDem‰πùÂπ¥Ôºâofi ÿØŸÜ ŸÑŸÑŸÖŸÜÿ≤ŸÑCOND*S–ù,Ÿàÿ±ÿ™ÿ±ÿπŸÖÂîëÂîëÂîëPlusODÊàëÂè™ÊòØÊÉ≥Ny Qu√°REPL(DPÂ∞±Âà∞ÈÇ£ÊàëQu ‡Æö‡ØÜ‡ÆØ‡Øç‡ÆØ‡Æ™‡Øç‡Æ™‡Æü‡Øç‡Æü‡ØÅolecular√¢']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "\n",
        "After completing the lab several times it's complex how the fine-tuning is accomplished. Sometimes it works well, others not, leaving a funny feeling about if what we are doing, it really matters. It seems completely random sometimes.\n",
        "\n",
        "In the last run, the model behaved erratic, answering with strange characters. Going back and executing everything from scratch seemed to clear things up. But again, fiddling with the Lora Config parameters is like playing with a gun.\n",
        "\n",
        "Anyway, I managed to get MLFlow work on my local server, so I think it was worth the effort.\n",
        "\n",
        "## What I learned\n",
        "\n",
        "* Fine-tuning can be challenging depending on the input parameters\n",
        "* MLFlow first runs to start to log every experiment\n",
        "* We'll come back to this lab again and try different things ahead on the course\n"
      ],
      "metadata": {
        "id": "Pla2vRz2waiS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nbq5_z4ByFzZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "80674eb6afe14df9869318218b6b4933": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a940bda862c4ea082914122d2c4ba45",
              "IPY_MODEL_bd5558eba6984e43afc4506119d15f11",
              "IPY_MODEL_d00c11fc4dee4c6987988f1dd516ce3c"
            ],
            "layout": "IPY_MODEL_0ac6cc32fb6e4940a90165248e3e403b"
          }
        },
        "8a940bda862c4ea082914122d2c4ba45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fc6bacae7684b12b78c427dbc35d875",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3c27ba426033499baa794beb8aa7761a",
            "value": "Map:‚Äá100%"
          }
        },
        "bd5558eba6984e43afc4506119d15f11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44e11f3d154a4f51a605c9bee400f542",
            "max": 513,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_28b4a2ee7e6d4a8287b32c7379936ac9",
            "value": 513
          }
        },
        "d00c11fc4dee4c6987988f1dd516ce3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc63874f46464af0b6b3fff28a71c45e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8f0fbd8d9af34f41b2f97512eced21df",
            "value": "‚Äá513/513‚Äá[00:00&lt;00:00,‚Äá1881.00‚Äáexamples/s]"
          }
        },
        "0ac6cc32fb6e4940a90165248e3e403b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fc6bacae7684b12b78c427dbc35d875": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c27ba426033499baa794beb8aa7761a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44e11f3d154a4f51a605c9bee400f542": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28b4a2ee7e6d4a8287b32c7379936ac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc63874f46464af0b6b3fff28a71c45e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f0fbd8d9af34f41b2f97512eced21df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}